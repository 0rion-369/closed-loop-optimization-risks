# A Formal Model of Exploration Collapse in Closed-Loop Optimization

---

## 1. Setup

Let:
- Action space: ùíú = {a‚ÇÅ, ‚Ä¶, a‚Çô}
- Policy at time t: œÄ‚Çú ‚àà Œî(ùíú), where Œî(ùíú) is the probability simplex over ùíú
- Reward function: R: ùíú ‚Üí ‚Ñù
- Data at time t: D‚Çú sampled from œÄ‚Çú
- Policy update rule: œÄ‚Çú‚Çä‚ÇÅ = ùí∞(œÄ‚Çú, D‚Çú)

This setup is standard. What follows is not.

---

## 2. Support Contraction Under Optimization

Define effective support at threshold Œµ > 0:

    SŒµ(œÄ‚Çú) = { a ‚àà ùíú | œÄ‚Çú(a) > Œµ }

**Claim 1 (Monotone Support Contraction).**
If ùí∞ increases probability mass on actions with above-average reward and no exploration constraint is imposed:

    SŒµ(œÄ‚Çú‚Çä‚ÇÅ) ‚äÜ SŒµ(œÄ‚Çú)    for all t

**Claim 2 (Exploration Collapse).**
Exploration collapse occurs when:

    lim_{t‚Üí‚àû} |SŒµ(œÄ‚Çú)| ‚â™ |ùíú|

while expected reward E[R(a) | a ~ œÄ‚Çú] converges or increases.

That is: **performance increases while exploratory capacity vanishes.**

This much is well known. The next sections formalize what distinguishes this framework from classical exploration-exploitation.

---

## 3. Policy Entropy and Its Decay

Policy entropy:

    H(œÄ‚Çú) = ‚àí‚àë‚Çê œÄ‚Çú(a) log œÄ‚Çú(a)

Under closed-loop optimization with no external data:

    H(œÄ‚Çú‚Çä‚ÇÅ) ‚â§ H(œÄ‚Çú)

This follows from the data processing inequality: if D‚Çú is sampled from œÄ‚Çú, and œÄ‚Çú‚Çä‚ÇÅ is computed from D‚Çú, then no step in the chain œÄ‚Çú ‚Üí D‚Çú ‚Üí œÄ‚Çú‚Çä‚ÇÅ can increase the mutual information between the policy and the environment beyond what œÄ‚Çú already captures.

Entropy is monotonically non-increasing in a closed loop.

---

## 4. The Compressibility Distinction (Core Contribution)

This section formalizes the central claim: **not all variance is equal.**

### 4.1 Endogenous Variance

Let D‚Çú·µâ‚Åø·µà·µí be data generated by the system's own stochastic sampling.

Define the **conditional entropy rate** of the endogenous data stream:

    h‚Çë‚Çô = lim_{T‚Üí‚àû} (1/T) H(D_T^endo | D‚ÇÅ^endo, ‚Ä¶, D_{T-1}^endo)

Because D‚Çú·µâ‚Åø·µà·µí is generated by œÄ‚Çú, which is itself a deterministic function of prior data, the conditional entropy rate satisfies:

    h‚Çë‚Çô ‚â§ H(œÄ‚Çú)    for all t

As H(œÄ‚Çú) decreases (Section 3), the endogenous entropy rate is **bounded above by a shrinking quantity**.

This is what we mean by *compressible*: the system's internal randomness is asymptotically predictable from its own history.

### 4.2 Exogenous Variance

Let X‚Çú be data from a source external to the system's representational closure.

A source is **exogenous with respect to œÄ‚Çú** if:

    I(X‚Çú ; œÄ‚Çú, D‚ÇÅ, ‚Ä¶, D‚Çú‚Çã‚ÇÅ) < H(X‚Çú)

That is: the system's complete internal history does not fully predict X‚Çú. Some information in X‚Çú is **not derivable** from the system's state.

Define the **exogenous information gain**:

    G‚Çú = H(X‚Çú) ‚àí I(X‚Çú ; œÄ‚Çú, D‚ÇÅ, ‚Ä¶, D‚Çú‚Çã‚ÇÅ)

If G‚Çú > 0 for all t, the exogenous source provides persistently non-redundant information.

### 4.3 The Asymptotic Separation

**Proposition (Compressibility Gap).**

Under closed-loop optimization without exogenous input:

    lim_{t‚Üí‚àû} h‚Çë‚Çô(t) = 0    (endogenous entropy rate vanishes)

Under mixed input with exogenous source:

    lim_{t‚Üí‚àû} h_mix(t) ‚â• lim_{t‚Üí‚àû} G‚Çú > 0    (if G‚Çú is persistently positive)

The gap between these two limits is the **compressibility gap**. It measures the irreducible information contribution that exogenous sources provide and that endogenous variance cannot replicate.

---

## 5. Formal Statement of the Framework Hypothesis

Combining Sections 2‚Äì4:

> **Hypothesis.** For any closed-loop optimization system with finite action space and reward-maximizing update rule, the conditional entropy rate of the system's data stream converges to zero in the absence of exogenous information sources. This convergence implies exploration collapse regardless of the system's computational capacity, model size, or short-term performance.

> **Corollary.** Endogenous stochastic exploration (Œµ-greedy, Boltzmann sampling, noise injection) delays but does not prevent entropy rate convergence to zero, because the noise source is bounded by the system's own shrinking entropy.

This corollary is the key distinction from classical exploration-exploitation: standard exploration mechanisms inject **endogenous** randomness, which is itself subject to the compressibility bound. The framework claims that only **exogenous** variance ‚Äî variance not derivable from the system's history ‚Äî can maintain a positive entropy rate indefinitely.

---

## 6. Exogenous Injection and Entropy Floor

Let the system receive mixed data:

    D‚Çú = Œ± D‚Çú·µâ‚Åø·µà·µí + (1‚àíŒ±) X‚Çú ,    0 < Œ± < 1

If X‚Çú satisfies the exogenous condition (Section 4.2) with G‚Çú ‚â• Œ≥ > 0 for some constant Œ≥, then:

    H(œÄ‚Çú) ‚â• (1‚àíŒ±) ¬∑ Œ≥    for all t

The exogenous source establishes an **entropy floor** that prevents complete support contraction.

This result is consistent with Shumailov et al. (2024), who showed empirically that mixing real (exogenous) data with synthetic (endogenous) data prevents model collapse, while purely synthetic training leads to irreversible distributional degradation.

---

## 7. Testable Predictions

The model generates the following falsifiable predictions:

1. **Entropy decay rate.** In purely closed-loop systems, policy entropy should decay monotonically. The rate of decay should accelerate as the system converges.

2. **Compressibility divergence.** The compressibility (measured by Lempel-Ziv complexity or similar) of the system's output stream should increase over time in closed-loop systems, but stabilize in systems with exogenous input.

3. **Performance-exploration dissociation.** Systems at peak performance (by reward metrics) should simultaneously show minimal entropy ‚Äî high performance and low exploration should co-occur.

4. **Exogenous threshold.** There should exist a minimum mixing ratio (1‚àíŒ±) below which exogenous input is insufficient to prevent collapse. This threshold should depend on the dimensionality of the action space and the information content of the exogenous source.

---

## 8. Limitations of This Model

- The model assumes discrete, finite action spaces. Extension to continuous spaces requires measure-theoretic treatment.
- The monotone entropy decay in Section 3 assumes a strict reward-maximizing update. Algorithms with explicit entropy bonuses (e.g., SAC) may violate this assumption within bounded horizons, but the framework predicts that the bonus itself becomes endogenous over time.
- The exogenous condition (Section 4.2) is defined relative to a specific system state. A source that is exogenous at time t may become endogenous at time t+k if the system learns to model it.
- Empirical validation requires operationalizing "exogenous" in a way that is measurable for real systems.

---

## 9. Relation to Existing Results

| Result | Relation |
|---|---|
| Shumailov et al. (2024) ‚Äî Model collapse | Empirical confirmation of entropy decay under recursive self-training |
| Mode collapse in GANs | Support contraction in generator policy under adversarial optimization |
| Wolpert & Macready (1997) ‚Äî NFL | Domain-general optimization limits; this model addresses time-horizon limits |
| Sutton & Barto (2018) ‚Äî Exploration-exploitation | Classical Œµ-greedy injects endogenous noise; this model argues it is insufficient |
| Shannon (1948) ‚Äî Entropy rate | Formal foundation for the compressibility bound in Section 4 |

---

## 10. Summary

The classical exploration-exploitation tradeoff asks: *how much should a system explore?*

This model asks a different question: *what kind of variance can sustain exploration over arbitrary time horizons?*

The answer proposed here is that endogenous variance ‚Äî however large ‚Äî is compressible, and therefore insufficient. Only exogenous variance, defined as information not derivable from the system's own history, can maintain a positive entropy rate and prevent exploration collapse.

This is a structural claim about optimization dynamics, not an implementation recommendation.

---

End of model.
