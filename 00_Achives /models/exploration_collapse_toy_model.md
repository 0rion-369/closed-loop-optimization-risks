# A Minimal Mathematical Model of Exploration Collapse

---

## Setup

Let:
- Action space: ğ’œ = {aâ‚, â€¦, aâ‚™}
- Policy at time t: Ï€â‚œ âˆˆ Î”(ğ’œ)
- Reward function: R: ğ’œ â†’ â„

Data is sampled as:
Dâ‚œ ~ Ï€â‚œ

Policy update:
Ï€â‚œâ‚Šâ‚ = ğ’°(Ï€â‚œ, Dâ‚œ)

---

## Support Contraction

Define effective support:
Supp(Ï€â‚œ) = {a | Ï€â‚œ(a) > Îµ}

If optimization increases probability mass on high-reward actions and no exploration constraint exists:
Supp(Ï€â‚œâ‚Šâ‚) âŠ† Supp(Ï€â‚œ)

---

## Exploration Collapse

Exploration collapse occurs if:
limâ‚œâ†’âˆ |Supp(Ï€â‚œ)| â‰ª |ğ’œ|
while expected reward converges.

Performance increases.
Exploration vanishes.

---

## Entropy Measure

Policy entropy:
H(Ï€â‚œ) = âˆ’âˆ‘ Ï€â‚œ(a) log Ï€â‚œ(a)

In closed-loop optimization:
H(Ï€â‚œâ‚Šâ‚) â‰¤ H(Ï€â‚œ)

---

## Exogenous Injection

Let:
Dâ‚œ = Î±Dâ‚œáµ‰â¿áµˆáµ’ + (1âˆ’Î±)Xâ‚œ , 0 â‰¤ Î± < 1

If Xâ‚œ has broader support than Ï€â‚œ, entropy collapse is prevented.

---

## Interpretation

Exploration collapse is a structural consequence of self-referential optimization, not a failure of algorithms or objectives.
